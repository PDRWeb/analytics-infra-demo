# Docker Stack configuration for analytics-infra-demo
# Deploy with: docker stack deploy -c docker-stack.yml analytics-stack
version: '3.8'

services:
  # Database services
  postgres_main:
    image: postgres:15
    environment:
      POSTGRES_USER: ${MAIN_DB_USER}
      POSTGRES_PASSWORD: ${MAIN_DB_PASS}
      POSTGRES_DB: ${MAIN_DB_NAME}
    volumes:
      - postgres_main_data:/var/lib/postgresql/data
      - ./database/backups:/backups
      - ./database/sql:/sql
      - ./demo_data:/csv
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${MAIN_DB_USER} -d ${MAIN_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  holding_db:
    image: postgres:15
    environment:
      POSTGRES_USER: ${HOLDING_DB_USER}
      POSTGRES_PASSWORD: ${HOLDING_DB_PASS}
      POSTGRES_DB: ${HOLDING_DB_NAME}
    volumes:
      - holding_db_data:/var/lib/postgresql/data
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${HOLDING_DB_USER} -d ${HOLDING_DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  dead-letter-queue:
    image: postgres:15
    environment:
      POSTGRES_USER: ${DLQ_DB_USER:-dlq_user}
      POSTGRES_PASSWORD: ${DLQ_DB_PASS:-your_secure_dlq_password}
      POSTGRES_DB: ${DLQ_DB_NAME:-dead_letter_queue}
    volumes:
      - dlq_data:/var/lib/postgresql/data
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DLQ_DB_USER:-dlq_user} -d ${DLQ_DB_NAME:-dead_letter_queue}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Monitoring services
  prometheus:
    image: prom/prometheus:v2.45.0
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:10.0.0
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  node-exporter:
    image: prom/node-exporter:v1.6.0
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - analytics_net
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 128M
          cpus: '0.1'
        reservations:
          memory: 64M
          cpus: '0.05'

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.13.2
    environment:
      DATA_SOURCE_NAME: "postgresql://${MAIN_DB_USER}:${MAIN_DB_PASS}@postgres_main:5432/${MAIN_DB_NAME}?sslmode=disable"
    networks:
      - analytics_net
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          memory: 128M
          cpus: '0.1'
        reservations:
          memory: 64M
          cpus: '0.05'

  # Logging services
  loki:
    image: grafana/loki:2.9.0
    volumes:
      - ./logging/loki-config.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - ./logging/promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - analytics_net
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 128M
          cpus: '0.1'
        reservations:
          memory: 64M
          cpus: '0.05'

  grafana-logs:
    image: grafana/grafana:10.0.0
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_LOGS_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_logs_data:/var/lib/grafana
      - ./logging/grafana-logs/provisioning:/etc/grafana/provisioning
      - ./logging/grafana-logs/dashboards:/var/lib/grafana/dashboards
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Application services
  api-receiver:
    image: ${DOCKERHUB_USERNAME}/analytics-infra-api-receiver:latest
    environment:
      PORT: 8080
      API_KEY: ${API_KEY}
      DB_HOST: holding_db
      DB_PORT: 5432
      DB_USER: ${HOLDING_DB_USER}
      DB_PASS: ${HOLDING_DB_PASS}
      DB_NAME: ${HOLDING_DB_NAME}
    networks:
      - analytics_net
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  sync-job:
    image: ${DOCKERHUB_USERNAME}/analytics-infra-sync-job:latest
    environment:
      DB_HOST: holding_db
      DB_PORT: 5432
      DB_USER: ${HOLDING_DB_USER}
      DB_PASS: ${HOLDING_DB_PASS}
      DB_NAME: ${HOLDING_DB_NAME}
      MAIN_DB_HOST: postgres_main
      MAIN_DB_PORT: 5432
      MAIN_DB_USER: ${MAIN_DB_USER}
      MAIN_DB_PASS: ${MAIN_DB_PASS}
      MAIN_DB_NAME: ${MAIN_DB_NAME}
    networks:
      - analytics_net
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    command: ["python", "sync_job.py"]

  data-validator:
    image: ${DOCKERHUB_USERNAME}/analytics-infra-data-validator:latest
    environment:
      DB_HOST: holding_db
      DB_PORT: 5432
      DB_USER: ${HOLDING_DB_USER}
      DB_PASS: ${HOLDING_DB_PASS}
      DB_NAME: ${HOLDING_DB_NAME}
      DLQ_DB_HOST: dead-letter-queue
      DLQ_DB_PORT: 5432
      DLQ_DB_USER: ${DLQ_DB_USER:-dlq_user}
      DLQ_DB_PASS: ${DLQ_DB_PASS:-your_secure_dlq_password}
      DLQ_DB_NAME: ${DLQ_DB_NAME:-dead_letter_queue}
      VALIDATION_INTERVAL: 30
    networks:
      - analytics_net
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  health-monitor:
    image: ${DOCKERHUB_USERNAME}/analytics-infra-health-monitor:latest
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - API_RECEIVER_URL=http://api-receiver:8080
      - METABASE_URL=http://metabase:3000
      - HOLDING_DB_USER=${HOLDING_DB_USER}
      - HOLDING_DB_PASS=${HOLDING_DB_PASS}
      - HOLDING_DB_NAME=${HOLDING_DB_NAME}
      - MAIN_DB_USER=${MAIN_DB_USER}
      - MAIN_DB_PASS=${MAIN_DB_PASS}
      - MAIN_DB_NAME=${MAIN_DB_NAME}
    networks:
      - analytics_net
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3
      resources:
        limits:
          memory: 128M
          cpus: '0.1'
        reservations:
          memory: 64M
          cpus: '0.05'

  # Database initialization
  db-init:
    image: postgres:15
    environment:
      POSTGRES_USER: ${MAIN_DB_USER}
      POSTGRES_PASSWORD: ${MAIN_DB_PASS}
      POSTGRES_DB: ${MAIN_DB_NAME}
      METABASE_APP_DB_NAME: ${METABASE_APP_DB_NAME:-metabase}
      MAIN_DB_USER: ${MAIN_DB_USER}
      MAIN_DB_PASS: ${MAIN_DB_PASS}
      MAIN_DB_HOST: postgres_main
      MAIN_DB_PORT: 5432
    volumes:
      - ./scripts/init-metabase-db.sh:/init-metabase-db.sh
    networks:
      - analytics_net
    deploy:
      replicas: 1
      restart_policy:
        condition: none
      placement:
        constraints:
          - node.role == manager
    command: >
      bash -c "
        chmod +x /init-metabase-db.sh &&
        /init-metabase-db.sh
      "

  # Visualization services
  metabase:
    image: metabase/metabase:latest
    environment:
      MB_JETTY_PORT: 3000
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: ${METABASE_APP_DB_NAME:-metabase}
      MB_DB_PORT: 5432
      MB_DB_USER: ${MAIN_DB_USER}
      MB_DB_PASS: ${MAIN_DB_PASS}
      MB_DB_HOST: postgres_main
      # Initial admin (first-run) and usability
      MB_SITE_NAME: ${MB_SITE_NAME:-Analytics Demo}
      MB_ADMIN_EMAIL: ${METABASE_ADMIN_EMAIL:-}
      MB_LOAD_SAMPLE_CONTENT: ${MB_LOAD_SAMPLE_CONTENT:-false}
      MB_LOAD_ANALYTICS_CONTENT: ${MB_LOAD_ANALYTICS_CONTENT:-true}
      MB_PASSWORD_COMPLEXITY: ${MB_PASSWORD_COMPLEXITY:-normal}
      MB_PASSWORD_LENGTH: ${MB_PASSWORD_LENGTH:-8}
      # Security and web settings
      MB_JETTY_HOST: 0.0.0.0
      MB_JETTY_REQUEST_HEADER_SIZE: ${MB_JETTY_REQUEST_HEADER_SIZE:-16384}
      MB_EMOJI_IN_LOGS: ${MB_EMOJI_IN_LOGS:-true}
      # CSP Configuration to fix UI issues
      MB_CONTENT_SECURITY_POLICY_NONCE: 'true'
      MB_CSP_SCRIPT_SRC: "'self' 'unsafe-inline' 'unsafe-eval' https://maps.google.com https://accounts.google.com"
      MB_CSP_STYLE_SRC: "'self' 'unsafe-inline' https://accounts.google.com"
      MB_CSP_FONT_SRC: "'self' data:"
      MB_CSP_IMG_SRC: "'self' data: https:"
      MB_CSP_CONNECT_SRC: "'self'"
      # Email (optional, for invites, alerts, password reset)
      MB_EMAIL_SMTP_HOST: ${MB_EMAIL_SMTP_HOST:-}
      MB_EMAIL_SMTP_PORT: ${MB_EMAIL_SMTP_PORT:-587}
      MB_EMAIL_SMTP_USERNAME: ${MB_EMAIL_SMTP_USERNAME:-}
      MB_EMAIL_SMTP_PASSWORD: ${MB_EMAIL_SMTP_PASSWORD:-}
      MB_EMAIL_SMTP_SECURITY: ${MB_EMAIL_SMTP_SECURITY:-starttls}
      MB_EMAIL_FROM_ADDRESS: ${MB_EMAIL_FROM_ADDRESS:-${METABASE_ADMIN_EMAIL}}
      # Other common opts
      MB_ANON_TRACKING_ENABLED: ${MB_ANON_TRACKING_ENABLED:-false}
      MB_SEND_NEW_SSO_USER_ADMIN_EMAIL: ${MB_SEND_NEW_SSO_USER_ADMIN_EMAIL:-false}
    volumes:
      - metabase_data:/metabase-data
    networks:
      - analytics_net
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_main_data:
    external: true
  holding_db_data:
    external: true
  dlq_data:
    external: true
  prometheus_data:
    external: true
  grafana_data:
    external: true
  grafana_logs_data:
    external: true
  loki_data:
    external: true
  metabase_data:
    external: true

networks:
  analytics_net:
    driver: overlay
    attachable: true
